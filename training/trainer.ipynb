{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f656f1-7de7-4d3b-9f47-25d88fdf1170",
   "metadata": {},
   "source": [
    "## Project of the course \"_Development of Intelligent Computer Systems_\": 1st Deliverable\n",
    "\n",
    "In the first part of this project, it's implemented all components of a training pipeline for a classification problem. Sequentially, these components and their descriptions are as follows:\n",
    "\n",
    "1. **Enviroment preparation** <br>\n",
    "    Import all packages and libs, and instantiate env variables for all next steps.\n",
    "\n",
    "2. **Data extraction** <br>\n",
    "    Loads a dataset with product data from a specified path available in the\n",
    "    environment variable `DATASET_PATH`.\n",
    "\n",
    "3. **Data preparation** <br>\n",
    "    Explore the data set, and process it for use in training and validation.\n",
    "\n",
    "4. **Modeling the problem** <br>\n",
    "    Specifies a model to handle the classification problem.\n",
    "\n",
    "5. **Model validation** <br>\n",
    "    Generates metrics about the model accuracy (precision, recall, F1, etc.)\n",
    "    for each category and exports them to a specified path available in the\n",
    "    environment variable `METRICS_PATH`\n",
    "\n",
    "6. **Export model** <br>\n",
    "    Exports a candidate model to a specified path available in the environment\n",
    "    variable `MODEL_PATH`.\n",
    "\n",
    "More specifically, we will train a model that should receive data related to products and return the best categories for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352d52d-5425-4793-90c5-1790ef9fc32f",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For this project, we will use data from an [open source dataset][1] made by [Elo7][2].\n",
    "It contains data based on Elo7's search engine usage.\n",
    "\n",
    "The columns composing each example in data are specified below:\n",
    "\n",
    "| **Field**           | **Description**                                                                              |\n",
    "| ------------------- | -------------------------------------------------------------------------------------------- |\n",
    "| `product_id`        | Product numeric identification                                                               |\n",
    "| `seller_id`         | Seller numeric identification                                                                |\n",
    "| `query`             | The text inserted by users                                                                   |\n",
    "| `search_page`       | The page number the product appeared (min 1 and max 5)                                       |\n",
    "| `position`          | The position the product appeared in the search page (min 0 and max 38)                      |\n",
    "| `title`             | Product title                                                                                |\n",
    "| `concatenated_tags` | Product tags inserted by the seller                                                          |\n",
    "| `creation_date`     | The date of product registration in Elo7 platform                                            |\n",
    "| `price`             | The product price (R$)                                                                       |\n",
    "| `weight`            | The weight (grams) of a product unit                                                         |\n",
    "| `express_delivery`  | Indicates if the product has already been made (1) or not (0)                                |\n",
    "| `minimum_quantity`  | The minimum quantity the seller sells the product                                            |\n",
    "| `view_counts`       | The number of times the product was clicked in the last three months                         |\n",
    "| `order_counts`      | The number of times the product was purchased in the last three months                       |\n",
    "| `category`          | Product category                                                                             |\n",
    "\n",
    "[1]: https://github.com/elo7/data7_oss/tree/master/elo7-search\n",
    "[2]: https://elo7.com.br/sobre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a13f2b-e765-46ad-b244-9603152be93d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122a2c9-7486-4896-9f57-bd410fafe56c",
   "metadata": {},
   "source": [
    "### Env. preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc2cc38-1cee-4034-b6f5-a010a7ac788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import spacy\n",
    "import pickle\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f45a4e8-49b3-4cca-a4cb-4d2b3e0e3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd03b41-f498-4f5d-882a-461f26f3470c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download trained NLP pipeline for Portuguese.\n",
    "# spaCy is a powerful NLP lib that offers a handful\n",
    "# of tools for advanced processing natural language.\n",
    "\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6879b3-e79d-444e-b8c3-d56d306fa165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an array containing Portuguese stop words.\n",
    "# These words were handwritten, and they are inside the file\n",
    "# stop_words.txt in this directory.\n",
    "pt_br_stop_words = []\n",
    "with open('./stop_words.txt') as f:\n",
    "    pt_br_stop_words = (\n",
    "        [word if len(word.split(' ')) == 1 else word.split(' ')[1] for word in f.read().split(',')]\n",
    "    )\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff5d89a-208a-4456-9219-c574924ba59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bc46b4-6a67-46d3-8224-0eb18aee3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.getenv(\"DATASET_PATH\")\n",
    "METRICS_PATH = os.getenv(\"METRICS_PATH\")\n",
    "MODEL_PATH = os.getenv(\"MODEL_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "357f97c7-126d-48d9-8db7-1b030a8e05c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /usr/src/data/sample_products.csv\n",
      "Metrics Path: /usr/src/data/metrics.txt\n",
      "Model Path: /usr/src/data/model.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Dataset Path: ' + DATASET_PATH + '\\n' + 'Metrics Path: ' + METRICS_PATH + '\\n' + 'Model Path: ' + MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12eaa5a-1aaf-4248-a6dd-be9799048d53",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2338ac-6f22-4870-9f64-ebac9cab2f0d",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d95af81e-fc83-4bed-b901-e816650ec73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47bab597-acd2-481f-bbdd-407ab344e200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>query</th>\n",
       "      <th>search_page</th>\n",
       "      <th>position</th>\n",
       "      <th>title</th>\n",
       "      <th>concatenated_tags</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>express_delivery</th>\n",
       "      <th>minimum_quantity</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>order_counts</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11394449</td>\n",
       "      <td>8324141</td>\n",
       "      <td>espirito santo</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Mandala Esp√≠rito Santo</td>\n",
       "      <td>mandala mdf</td>\n",
       "      <td>2015-11-14 19:42:12</td>\n",
       "      <td>171.890000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Decora√ß√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15534262</td>\n",
       "      <td>6939286</td>\n",
       "      <td>cartao de visita</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Cart√£o de Visita</td>\n",
       "      <td>cartao visita panfletos tag adesivos copos lon...</td>\n",
       "      <td>2018-04-04 20:55:07</td>\n",
       "      <td>77.670000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Papel e Cia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16153119</td>\n",
       "      <td>9835835</td>\n",
       "      <td>expositor de esmaltes</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>Organizador expositor p/ 70 esmaltes</td>\n",
       "      <td>expositor</td>\n",
       "      <td>2018-10-13 20:57:07</td>\n",
       "      <td>73.920006</td>\n",
       "      <td>2709.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15877252</td>\n",
       "      <td>8071206</td>\n",
       "      <td>medidas lencol para berco americano</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Jogo de Len√ßol Ber√ßo Estampado</td>\n",
       "      <td>t jogo lencol menino lencol berco</td>\n",
       "      <td>2017-02-27 13:26:03</td>\n",
       "      <td>118.770004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beb√™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15917108</td>\n",
       "      <td>7200773</td>\n",
       "      <td>adesivo box banheiro</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>ADESIVO BOX DE BANHEIRO</td>\n",
       "      <td>adesivo box banheiro</td>\n",
       "      <td>2017-05-09 13:18:38</td>\n",
       "      <td>191.810000</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Decora√ß√£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  seller_id                                query  search_page  \\\n",
       "0    11394449    8324141                       espirito santo            2   \n",
       "1    15534262    6939286                     cartao de visita            2   \n",
       "2    16153119    9835835                expositor de esmaltes            1   \n",
       "3    15877252    8071206  medidas lencol para berco americano            1   \n",
       "4    15917108    7200773                 adesivo box banheiro            3   \n",
       "\n",
       "   position                                 title  \\\n",
       "0         6                Mandala Esp√≠rito Santo   \n",
       "1         0                      Cart√£o de Visita   \n",
       "2        38  Organizador expositor p/ 70 esmaltes   \n",
       "3         6        Jogo de Len√ßol Ber√ßo Estampado   \n",
       "4        38               ADESIVO BOX DE BANHEIRO   \n",
       "\n",
       "                                   concatenated_tags        creation_date  \\\n",
       "0                                        mandala mdf  2015-11-14 19:42:12   \n",
       "1  cartao visita panfletos tag adesivos copos lon...  2018-04-04 20:55:07   \n",
       "2                                          expositor  2018-10-13 20:57:07   \n",
       "3                  t jogo lencol menino lencol berco  2017-02-27 13:26:03   \n",
       "4                               adesivo box banheiro  2017-05-09 13:18:38   \n",
       "\n",
       "        price  weight  express_delivery  minimum_quantity  view_counts  \\\n",
       "0  171.890000  1200.0                 1                 4          244   \n",
       "1   77.670000     8.0                 1                 5          124   \n",
       "2   73.920006  2709.0                 1                 1           59   \n",
       "3  118.770004     0.0                 1                 1          180   \n",
       "4  191.810000   507.0                 1                 6           34   \n",
       "\n",
       "   order_counts     category  \n",
       "0           NaN    Decora√ß√£o  \n",
       "1           NaN  Papel e Cia  \n",
       "2           NaN       Outros  \n",
       "3           1.0         Beb√™  \n",
       "4           NaN    Decora√ß√£o  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af6f94c8-3578-42af-9526-c60dcb9bf8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38000 entries, 0 to 37999\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   product_id         38000 non-null  int64  \n",
      " 1   seller_id          38000 non-null  int64  \n",
      " 2   query              38000 non-null  object \n",
      " 3   search_page        38000 non-null  int64  \n",
      " 4   position           38000 non-null  int64  \n",
      " 5   title              38000 non-null  object \n",
      " 6   concatenated_tags  37998 non-null  object \n",
      " 7   creation_date      38000 non-null  object \n",
      " 8   price              38000 non-null  float64\n",
      " 9   weight             37942 non-null  float64\n",
      " 10  express_delivery   38000 non-null  int64  \n",
      " 11  minimum_quantity   38000 non-null  int64  \n",
      " 12  view_counts        38000 non-null  int64  \n",
      " 13  order_counts       17895 non-null  float64\n",
      " 14  category           38000 non-null  object \n",
      "dtypes: float64(3), int64(7), object(5)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10f55d3-58de-445e-9903-2862c995e317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Decora√ß√£o', 'Papel e Cia', 'Outros', 'Beb√™', 'Lembrancinhas',\n",
       "       'Bijuterias e J√≥ias'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26382d-c83e-4a15-9b04-c7cf946e9188",
   "metadata": {},
   "source": [
    "Looking at the data for the first time, and its description [above](#Data), allows us to hypothesize\n",
    "that  for the task of correctly classifying the category of a product, text variables may have larger \n",
    "influence on target variable than, for instance, **creation_date** or **price** have. There also are \n",
    "fields (columns) that intuitively don't offer much information about product's category. For example, \n",
    "**creation_date**,  **price** and **weight** have high variance inside categories with such high abstraction \n",
    "(38k products to _only_ 6 categories).\n",
    "\n",
    "Moreover, text fields - **query**, **title** and **concatenated_tags** - ease the process of data preparation,\n",
    "given that they are (almost) all present in the dataset. Since only two samples in **concatenated_tags** are\n",
    "_Null_ (in a 38k sample space), it won't harm performance removing these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c4a9f9-cac1-43d3-bd45-fbddce04ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bda24ed1-a0e6-4ddf-ba42-d23495ec8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['seq'] = df2['query'] + ' ' + df2['title'] + ' ' + df2['concatenated_tags']\n",
    "seq_column = df2.pop('seq')\n",
    "df2.insert(0, 'seq', seq_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d5fe88-9d68-4c16-9dbc-163c37560b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['seq', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc9e027-3399-495e-9f6f-55c8629abd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>espirito santo Mandala Esp√≠rito Santo mandala mdf</td>\n",
       "      <td>Decora√ß√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cartao de visita Cart√£o de Visita cartao visit...</td>\n",
       "      <td>Papel e Cia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expositor de esmaltes Organizador expositor p/...</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medidas lencol para berco americano Jogo de Le...</td>\n",
       "      <td>Beb√™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adesivo box banheiro ADESIVO BOX DE BANHEIRO a...</td>\n",
       "      <td>Decora√ß√£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq     category\n",
       "0  espirito santo Mandala Esp√≠rito Santo mandala mdf    Decora√ß√£o\n",
       "1  cartao de visita Cart√£o de Visita cartao visit...  Papel e Cia\n",
       "2  expositor de esmaltes Organizador expositor p/...       Outros\n",
       "3  medidas lencol para berco americano Jogo de Le...         Beb√™\n",
       "4  adesivo box banheiro ADESIVO BOX DE BANHEIRO a...    Decora√ß√£o"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ecab42-e5d8-4bae-bb46-cd7ba34cf09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset=['seq'], inplace=True)\n",
    "df2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c3ff9-d440-4409-a2b3-40995f0f334b",
   "metadata": {},
   "source": [
    "To prepare text data to any model, preprocessing it is paramount. A list of preprocessing\n",
    "steps used to prepare the text data are described below:\n",
    "\n",
    "* **Disable Case Sensitivity** <br>\n",
    "Words at the beginning of sentences or even errors when writing make the text has both \n",
    "uppercase and lowercase letters for two words that, in many cases are the same word. \n",
    "Therefore, converting the text to capital letters or lowercase is required, avoiding this redundancy.\n",
    "\n",
    "* **Stopwords Removal** <br>\n",
    "Stopwords are words that do not carry an intrinsic meaning, but generally serve\n",
    "as connecting bridges between sentences within a sentence. Prepositions, conjunctions,\n",
    "articles are some of the stopwords categories. As in almost all sentences these\n",
    "words are used, there is no addition of information to define what is the category \n",
    "of a product from the stopwords inside the sentence. Some examples of Portuguese stopwords:\n",
    "\n",
    "> [de, a, o, que, e, do, da, em, um, para, com, uma, os, no, se, na, por, mais, as, dos, como, mas, ao, ele, das, √†, seu, sua]\n",
    "\n",
    "* **Numbers Removal** <br>\n",
    "Our vector representation of the feature space is a representation that separates each\n",
    "word in a vector dimension. Thus, isolated numbers do not add information\n",
    "to the text, and often not even while they are in conjunction with the text's words.\n",
    "In this way, numbers present in the evaluations are removed, because statistically the\n",
    "words present in the text are more representative of the product's category than the\n",
    "numbers by itself.\n",
    "\n",
    "* **Punctuation Marks Removal** <br>\n",
    "Punctuation marks, like numbers, do not have as much significance for semantics'\n",
    "evaluation, and may be disregarded during the pre-processing step.\n",
    "\n",
    "* **Accent Marks Removal** <br>\n",
    "Especially in Portuguese, accent marks bring problems in texts, because there is \n",
    "no homogeneity by native speakers of the language. So, with the same purpose of the \n",
    "case-sensitivity definition, the same words with or without accent will be treated\n",
    "equally.\n",
    "\n",
    "* **Lemmatization** <br>\n",
    "Lemmatization is a well-known linguistic process in which a word is reduced to its\n",
    "basic inflection. This mapping is done through a dictionary of morphological analysis \n",
    "of words. The spaCy library has excellent tools and dictionaries for lemmatization.\n",
    "\n",
    "* **Single character word Removal** <br>\n",
    "Since textual data is mostly acquired from people's (informal) texts on the web, it's \n",
    "expected that it has errors and/or typos, like abbreviations. In this way, remove (possible) \n",
    "single character words helps reduce feature dimensionality and improve model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ac07b1-7e66-466c-81ea-ad27435b46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(df_column, stop_words=pt_br_stop_words, lemma_dict=nlp):\n",
    "\n",
    "    # Disable case sensitivity\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([word.lower() for word in seq.split(' ')])\n",
    "    )\n",
    "\n",
    "    # Removing stop words\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([word for word in seq.split(' ') if word not in pt_br_stop_words])\n",
    "    )\n",
    "\n",
    "    # Remove numbers\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([re.sub(r'\\d+', '', word) for word in seq.split(' ')])\n",
    "    )\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([\n",
    "            word.translate(\n",
    "                str.maketrans('','', string.punctuation)) for word in seq.split(' ')\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Remove accent marks\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([unidecode.unidecode(word) for word in seq.split(' ')])\n",
    "    )\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join(list(set(seq.split(' '))))\n",
    "    )\n",
    "\n",
    "    # Lemmatization\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([\n",
    "            word.lemma_ if word.pos_ == 'VERB' else str(word) for word in lemma_dict(seq) \n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Remove single char words\n",
    "    df_column = df_column.apply(\n",
    "        lambda seq: ' '.join([\n",
    "            word for word in seq.split(' ') if len(word) > 1\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    return df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fac22e4-6e67-4256-80ec-3685582be0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['seq'] = processText(df2['seq'])\n",
    "df2.rename(columns={'seq': 'seq_process'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac1a636-3f4c-4139-8aea-b73fa50025c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_process</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>santo mdf mandala espirito</td>\n",
       "      <td>Decora√ß√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canecas panfletos adesivos tag drink cartao vi...</td>\n",
       "      <td>Papel e Cia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expositor esmaltes organizador</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>americano jogo berco estampar menino medidas l...</td>\n",
       "      <td>Beb√™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adesivo banheiro box</td>\n",
       "      <td>Decora√ß√£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         seq_process     category\n",
       "0                         santo mdf mandala espirito    Decora√ß√£o\n",
       "1  canecas panfletos adesivos tag drink cartao vi...  Papel e Cia\n",
       "2                     expositor esmaltes organizador       Outros\n",
       "3  americano jogo berco estampar menino medidas l...         Beb√™\n",
       "4                               adesivo banheiro box    Decora√ß√£o"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e747d524-471d-4694-b426-21a5a7a20b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "df3 = df2.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df3['category'] = le.fit_transform(df3['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7cee7a8-eb54-4f4a-b69c-7279902f577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Beb√™', 'Bijuterias e J√≥ias', 'Decora√ß√£o', 'Lembrancinhas',\n",
       "       'Outros', 'Papel e Cia'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_cats = df3['category'].unique()\n",
    "sorted_cats.sort()\n",
    "le.inverse_transform(sorted_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb75a420-434e-4d2e-a16c-7255ee78f957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_process</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>santo mdf mandala espirito</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canecas panfletos adesivos tag drink cartao vi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expositor esmaltes organizador</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>americano jogo berco estampar menino medidas l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adesivo banheiro box</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         seq_process  category\n",
       "0                         santo mdf mandala espirito         2\n",
       "1  canecas panfletos adesivos tag drink cartao vi...         5\n",
       "2                     expositor esmaltes organizador         4\n",
       "3  americano jogo berco estampar menino medidas l...         0\n",
       "4                               adesivo banheiro box         2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d5ac42-9a3d-4fc3-878b-7a8a4fed4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37998 entries, 0 to 37997\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   seq_process  37998 non-null  object\n",
      " 1   category     37998 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 593.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b909540b-d7ec-4d43-87ce-bdc261d18c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6930\n",
       "1      940\n",
       "2     8722\n",
       "3    17524\n",
       "4     1132\n",
       "5     2750\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absolute class count\n",
    "val_count = df3['category'].value_counts()\n",
    "\n",
    "val_count.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659463da-894a-4e30-8fa3-18b761597944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18.237802\n",
       "1     2.473814\n",
       "2    22.953840\n",
       "3    46.118217\n",
       "4     2.979104\n",
       "5     7.237223\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage class count\n",
    "sum_val_count = val_count.values.sum()\n",
    "\n",
    "(100*val_count / sum_val_count).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e943ee-606c-4b25-b059-0d4a1d1d9711",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb020e7-6e35-4ca7-bb29-8a7f530f4905",
   "metadata": {},
   "source": [
    "### Train, validate, and export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0139521-178b-4e34-afa8-cb86e1ad86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, \n",
    " y_train, y_test) = train_test_split(df3['seq_process'], df3['category'], \n",
    "                                     test_size=.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5a99aeb-5f93-488f-8d59-5d95186da399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((24698,), (24698,)) ((13300,), (13300,))\n"
     ]
    }
   ],
   "source": [
    "print((X_train.shape, y_train.shape), (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797ae75-077f-4caf-9890-d2a40a67a07f",
   "metadata": {},
   "source": [
    "Since our independent variable is a text, we do need to transform it\n",
    "into a numerical vector. There are a variety of these feature extraction \n",
    "methods: _bag of words_ (BoW), _term frequency-inverse document frequency_ \n",
    "(TF-IDF), _word2vec_, _GloVe_, to name a few.\n",
    "\n",
    "Nevertheless, some of these methods (embedding ones) requires models \n",
    "pre-trained on the same language as the target one. Thus, those methods\n",
    "are discarded - _word2vec_ and _GloVe_ are some that fits into that category \n",
    "and were previously cited.\n",
    "\n",
    "In the set of remaining ones, TF-IDF has better word representations, due to\n",
    "its consideration of the word inverse frequency along all examples. This is important\n",
    "due to recurrency of some words along the dataset, and rareness of others. Briefly,\n",
    "words that are common along the examples won't affect the target variable. On the other\n",
    "hand, rare words, which would have less proeminency in methods like BoW, will have\n",
    "greater weight in the model's classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f684824d-d9ff-45d6-b1fc-08bc727ca6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-idf transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_X_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c6cea-6d2f-464e-b0a2-852a67c83749",
   "metadata": {},
   "source": [
    "On ML's zoo, ensemble methods stand out throughout different tasks. Thus,\n",
    "Gradient Boosting Classifier is (_a priori_) handpicked. Its hyperparameters\n",
    "were set in a trial and error fashion - grid search cross-val in a tree-based\n",
    "ensemble method takes to long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2abab6b8-014f-4917-8ad4-ebdd386f0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execu√ß√£o (s): 307.04\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "start_time = time.time()\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "        n_estimators=1000, learning_rate=0.1,                             \n",
    "        max_depth=3, random_state=0\n",
    "    ).fit(tfidf_X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(r'Tempo de execu√ß√£o (s): {end_time:.2f}'.format(end_time=end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e2f977d-3c2a-4791-b26a-3c9afe7d7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training data): 97.17%\n"
     ]
    }
   ],
   "source": [
    "print(r'Accuracy (Training data): {perc:.2f}%'.format(perc=100*clf.score(tfidf_X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d2a72c9-2a99-4652-b4e1-de0a60ce2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test data): 88.26%\n"
     ]
    }
   ],
   "source": [
    "# Model validation\n",
    "print(r'Accuracy (Test data): {perc:.2f}%'.format(perc=100*clf.score(tfidf_X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af92482d-aed1-4d29-846a-073274224fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      2426\n",
      "           1       0.91      0.92      0.92       331\n",
      "           2       0.89      0.89      0.89      3032\n",
      "           3       0.88      0.94      0.91      6164\n",
      "           4       0.81      0.63      0.71       385\n",
      "           5       0.82      0.69      0.75       962\n",
      "\n",
      "    accuracy                           0.88     13300\n",
      "   macro avg       0.87      0.82      0.84     13300\n",
      "weighted avg       0.88      0.88      0.88     13300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model validation\n",
    "print(classification_report(y_test, clf.predict(tfidf_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef9d586f-45d5-47f9-8035-24d4941deafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2017,    1,  121,  265,    2,   20],\n",
       "       [   0,  305,    2,   21,    2,    1],\n",
       "       [  66,   12, 2704,  191,   28,   31],\n",
       "       [ 135,    5,  122, 5802,   17,   83],\n",
       "       [   9,    5,   30,   88,  243,   10],\n",
       "       [  14,    6,   49,  218,    7,  668]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model validation\n",
    "confusion_matrix(y_test, clf.predict(tfidf_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1660f138-2837-41e8-a0d6-e60c3d04fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording classification metrics (precision, recall, f1 score, accuracy)\n",
    "with open(METRICS_PATH, 'w+') as f:\n",
    "    f.write(classification_report(y_test, clf.predict(tfidf_X_test)))\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3434f3e-a02b-4b47-8e3f-131abf97382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting model\n",
    "with open(MODEL_PATH, 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee52921c-697a-40d8-a7c3-dbe5d8f66740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading exported model (test purpose only!)\n",
    "# with open(MODEL_PATH, 'rb') as f:\n",
    "#     clf = pickle.load(f)\n",
    "\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2e451-933c-4d91-b68c-6f32bf673eca",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
